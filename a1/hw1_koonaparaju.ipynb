{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Page view count of wikipedia site \n",
    "This purpose of this notebook is to analyse the page view count of Wikipedia website. This notebook consistes mainly of three parts. The first section is downloading data from the Wikipedia api sites. The second section parses the data and the final section plots the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports and initializations \n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import requests \n",
    "import json \n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data \n",
    "Wikipedia provides two endpoints for downloading data. There is a legacy endpoint and newer ednpoint. The two endpoints are provided below. Following the endpoint we define some utility functions that are required for API and file io access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_legacy = 'https://wikimedia.org/api/rest_v1/metrics/legacy/pagecounts/aggregate/{project}/{access-site}/{granularity}/{start}/{end}'\n",
    "\n",
    "endpoint_pageviews = 'https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/{project}/{access}/{agent}/{granularity}/{start}/{end}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(endpoint,parameters):\n",
    "    call = requests.get(endpoint.format(**parameters), headers=headers)\n",
    "    if call.ok:\n",
    "        response = call.json()\n",
    "        return response\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_as_json(data, filepath):\n",
    "    with open(filepath, 'w') as json_file: \n",
    "        json.dump(data,json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_file(filepath):\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        return json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize parameters\n",
    "We initialize query parameters and headers needed for wikimedia api. Parameters will be updated as needed when actual data is quried by the api. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see: https://wikimedia.org/api/rest_v1/#!/Legacy_data/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end\n",
    "params_legacy = {\"project\" : \"en.wikipedia.org\",\n",
    "                 \"access-site\" : \"desktop-site\",\n",
    "                 \"granularity\" : \"monthly\",\n",
    "                 \"start\" : \"2001010100\",\n",
    "                # for end use 1st day of month following final month of data\n",
    "                 \"end\" : \"2018100100\"\n",
    "                    }\n",
    "\n",
    "# see: https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end\n",
    "params_pageviews = {\"project\" : \"en.wikipedia.org\",\n",
    "                    \"access\" : \"all-access\",\n",
    "                    \"agent\" : \"user\",\n",
    "                    \"granularity\" : \"monthly\",\n",
    "                    \"start\" : \"2001010100\",\n",
    "                    # for end use 1st day of month following final month of data\n",
    "                    \"end\" : '2018101000'\n",
    "                        }\n",
    "\n",
    "# Customize these with your own information\n",
    "headers = {\n",
    "    'User-Agent': 'https://github.com/koonaparaju',\n",
    "    'From': 'koonav@uw.edu'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy endpoint query \n",
    "The following code queries the legacy endpoint for monthly count. The acces-site parameter is changed twice to collect all the data. The results of the query are stored in separate json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_site_types = ['desktop-site', 'mobile-site']\n",
    "#The timestamp of the first hour/day/month to include, in YYYYMMDDHH format.\n",
    "start_year = '2007'\n",
    "start_month = '12'\n",
    "end_year = '2016'\n",
    "end_month = '08'\n",
    "for access_site in access_site_types:\n",
    "    params_legacy['access-site'] = access_site\n",
    "    params_legacy['start'] = '{}{}0100'.format(start_year, start_month)\n",
    "    params_legacy['end'] = '{}{}0100'.format(end_year, end_month)\n",
    "    resp = api_call(endpoint_legacy, params_legacy)\n",
    "    save_data_as_json(resp, 'pagecounts_{}_{}{}_{}{}.json'.format(access_site,start_year,start_month,end_year,end_month))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New endpoint query \n",
    "The following code queries the page view endpoint for monthly count. The acces-site parameter is changed twice to collect all the data. The results of the query are stored in separate json file. This code should be refactoed to a utility function. we have code repetition here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_site_types = ['desktop', 'mobile-app', 'mobile-web']\n",
    "#The timestamp of the first hour/day/month to include, in YYYYMMDDHH format.\n",
    "start_year = '2015'\n",
    "start_month = '07'\n",
    "end_year = '2020'\n",
    "end_month = '09'\n",
    "for access_site in access_site_types:\n",
    "    params_pageviews['access'] = access_site\n",
    "    params_pageviews['start'] = '{}{}0100'.format(start_year, start_month)\n",
    "    params_pageviews['end'] = '{}{}0100'.format(end_year, end_month)\n",
    "    resp = api_call(endpoint_pageviews, params_pageviews)\n",
    "    save_data_as_json(resp, 'pageviews_{}_{}{}_{}{}.json'.format(access_site,start_year,start_month,end_year,end_month))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aggregate moblie app and mobile web data for pageview below. This is an intermediate step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'2015070100': 3288755294, '2015080100': 3302333038, '2015090100': 3170203333, '2015100100': 3268499132, '2015110100': 3236601070, '2015120100': 3376275307, '2016010100': 3717836846, '2016020100': 3334862272, '2016030100': 3386684191, '2016040100': 3258764002, '2016050100': 3395033236, '2016060100': 3354790945, '2016070100': 3496573762, '2016080100': 3515819303, '2016090100': 3393285781, '2016100100': 3509283891, '2016110100': 3591044925, '2016120100': 3776543855, '2017010100': 4231961542, '2017020100': 3711761399, '2017030100': 3903493989, '2017040100': 3639623119, '2017050100': 3686687720, '2017060100': 3519383193, '2017070100': 3725059253, '2017080100': 3621406302, '2017090100': 3531604369, '2017100100': 3673120542, '2017110100': 3670012061, '2017120100': 3830136304, '2018010100': 4259282371, '2018020100': 3725680728, '2018030100': 4049874257, '2018040100': 3927398111, '2018050100': 4089188522, '2018060100': 3977766741, '2018070100': 4266113752, '2018080100': 4187362161, '2018090100': 3977120244, '2018100100': 4073789753, '2018110100': 4033380040, '2018120100': 4289054166, '2019010100': 4597597181, '2019020100': 4018109995, '2019030100': 4407290322, '2019040100': 4261664166, '2019050100': 4413766230, '2019060100': 4285985271, '2019070100': 4557266440, '2019080100': 4531756543, '2019090100': 4437958209, '2019100100': 4506591862, '2019110100': 4471241664, '2019120100': 4554269292, '2020010100': 4832149630, '2020020100': 4418801212, '2020030100': 4686270555, '2020040100': 5505741941, '2020050100': 5231700095, '2020060100': 4573975256, '2020070100': 4809714465, '2020080100': 4803308661})\n"
     ]
    }
   ],
   "source": [
    "pageviews_mobile_files = ['pageviews_mobile-app_201507_202009.json', 'pageviews_mobile-web_201507_202009.json']\n",
    "mobile_pageviews_view = defaultdict(int)\n",
    "for pageviews_mobile_file in pageviews_mobile_files:\n",
    "    items = read_json_file(pageviews_mobile_file)['items']\n",
    "    for item in items:\n",
    "        mobile_pageviews_view[item['timestamp']] += item[\"views\"]\n",
    "\n",
    "print(mobile_pageviews_view)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mergeing all the remaingin json files into intermedite dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = ['pageviews_desktop_201507_202009.json', 'pagecounts_mobile-site_200712_201608.json', 'pagecounts_desktop-site_200712_201608.json']\n",
    "final_data = defaultdict(dict)\n",
    "for json_file in json_files:\n",
    "    api = json_file.split('_')[0]\n",
    "    access_type = 'desktop' if 'desktop' in json_file else 'mobile'\n",
    "    items = read_json_file(pageviews_mobile_file)['items']\n",
    "    for item in items:\n",
    "        ts = item['timestamp']\n",
    "        final_data[ts][\"{}_{}_views\".format(api,access_type)] = item[\"views\"]\n",
    "\n",
    "for k,v in mobile_pageviews_view.items():\n",
    "    final_data[k]['pageviews_mobile_views'] = v\n",
    "#print(final_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a list of dictionaries below to persist to a final csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_objects = []\n",
    "for ts, data_item in final_data.items():\n",
    "    year = ts[0:4]\n",
    "    month = ts[4:6]\n",
    "    pagecount_all_views = data_item.get('pagecounts_desktop_views',0)+ data_item.get('pagecounts_mobile_views',0)\n",
    "    pageview_all_views = data_item.get('pageviews_desktop_views',0) + data_item.get('pageviews_mobile_views',0)\n",
    "    data_item['year'] = year\n",
    "    data_item['month'] = month\n",
    "    data_item['pagecount_all_views'] = pagecount_all_views\n",
    "    data_item['pageview_all_views'] = pageview_all_views\n",
    "    csv_objects.append(data_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We persist the final csv final with the details needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('en-wikipedia_traffic_200712-202008.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = csv_objects[0].keys()\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(csv_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
